from __future__ import annotations

from typing import List, Literal

from pydantic import BaseModel, Field


class TotHypothesis(BaseModel):
    """Single hypothesis generated by the Phase 3A ToT reasoning."""

    factor: str = Field(
        ...,
        description="Concise description of the primary factor affecting readiness.",
        min_length=1,
    )
    evidence: str = Field(
        ...,
        description="Narrative explaining why this factor matters, with concrete data points.",
        min_length=1,
    )
    confidence: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Confidence score in [0,1] reflecting evidence strength.",
    )
    supporting_metrics: List[str] = Field(
        default_factory=list,
        description="Optional list of metric identifiers referenced in the evidence.",
    )


class TotResponse(BaseModel):
    """Structured output for the ToT reasoning node."""

    hypotheses: List[TotHypothesis] = Field(
        ..., min_length=1, description="Collection of ranked hypotheses." 
    )


class CritiqueIssue(BaseModel):
    """An issue raised by the critique node about the ToT analysis."""

    statement: str = Field(
        ...,
        description="Quoted portion of the hypothesis or finding that is problematic.",
        min_length=1,
    )
    reason: str = Field(
        ...,
        description="Explanation of why the statement is flawed or risky.",
        min_length=1,
    )
    severity: Literal["low", "medium", "high"] = Field(
        ...,
        description="Severity rating: low=minor wording, medium=requires revision, high=critical risk.",
    )


class CritiqueSuggestion(BaseModel):
    """Actionable improvement proposed by the critique node."""

    target_factor: str = Field(
        ...,
        description="Factor or insight the suggestion refers to.",
        min_length=1,
    )
    recommendation: str = Field(
        ...,
        description="Concrete recommendation to improve the hypothesis set.",
        min_length=1,
    )


class CritiqueResponse(BaseModel):
    """Structured critique output used in revision and downstream nodes."""

    issues: List[CritiqueIssue] = Field(
        default_factory=list, description="List of detected issues; empty if none found."
    )
    suggestions: List[CritiqueSuggestion] = Field(
        default_factory=list,
        description="Improvement suggestions mapped to specific factors.",
    )
    overall_confidence: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Confidence score in [0,1] for the hypotheses overall.",
    )


__all__ = [
    "TotHypothesis",
    "TotResponse",
    "CritiqueIssue",
    "CritiqueSuggestion",
    "CritiqueResponse",
]
