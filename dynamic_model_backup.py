#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dynamic Readiness Model v2.0 - åŠ¨æ€å‡†å¤‡åº¦è¯„ä¼°æ¨¡å‹
æ ¸å¿ƒè®¾è®¡ï¼šä¸¥æ ¼åˆ†ç¦»å…ˆéªŒ(Prior)å’ŒåéªŒ(Posterior)çš„åŠ¨æ€æ›´æ–°ç³»ç»Ÿ

============================================================================
â˜…â˜…â˜… æ¦‚ç‡è¡¨ç»“æ„è¯´æ˜ â˜…â˜…â˜…
============================================================================

ã€å…ˆéªŒæ¦‚ç‡è®¡ç®—éƒ¨åˆ† - PRIOR PROBABILITYã€‘
ä½¿ç”¨çš„æ¦‚ç‡è¡¨ï¼š
1. BASELINE_TRANSITION_CPT - åŸºçº¿çŠ¶æ€è½¬ç§»æ¦‚ç‡
2. TRAINING_LOAD_CPT - è®­ç»ƒè´Ÿè·å½±å“ 
3. ALCOHOL_CONSUMPTION_CPT - é…’ç²¾æ‘„å…¥å½±å“
4. LATE_CAFFEINE_CPT - æ·±å¤œå’–å•¡å› å½±å“
5. SCREEN_BEFORE_BED_CPT - ç¡å‰å±å¹•å½±å“
6. MENSTRUAL_PHASE_CPT - æœˆç»å‘¨æœŸå½±å“
7. LATE_MEAL_CPT - ç¡å‰è¿›é£Ÿå½±å“

ã€åéªŒæ¦‚ç‡è®¡ç®—éƒ¨åˆ† - POSTERIOR PROBABILITY (æŒ‡çº¹åº“)ã€‘
ä½¿ç”¨çš„æ¦‚ç‡è¡¨ï¼š
1. EMISSION_CPT - ä¸»è¦ç—‡çŠ¶æŒ‡çº¹åº“ P(Evidence | State)
2. INTERACTION_CPT_SORENESS_STRESS - äº¤äº’æ•ˆåº”æŒ‡çº¹åº“

============================================================================

è®¾è®¡åŸåˆ™ï¼š
- Prior(é¢„æµ‹): åŸºäºå‰ä¸€å¤©çš„æ‰€æœ‰åŸå› ï¼Œæ¯å¤©è®¡ç®—ä¸€æ¬¡ä¸”å›ºå®šä¸å˜
- Posterior(è¯Šæ–­): åŸºäºå›ºå®šPriorå’Œå½“å¤©ä¸æ–­ç´¯ç§¯çš„è¯æ®è¿›è¡Œå¤šæ¬¡å®æ—¶æ›´æ–°
- æŒ‡çº¹åº“: æè¿°æ¯ç§çŠ¶æ€ä¸‹å‡ºç°å„ç§ç—‡çŠ¶çš„æ¦‚ç‡åˆ†å¸ƒ
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import json

# =======================================================================
# â˜…â˜…â˜… æŒ‡çº¹åº“ (EMISSION CPT) - ç”¨äºåéªŒæ¦‚ç‡è®¡ç®— â˜…â˜…â˜…
# P(Evidence | State) - ç—‡çŠ¶æŒ‡çº¹åº“ï¼ŒåŸºäº6ç§å‡†å¤‡åº¦çŠ¶æ€çš„ç—‡çŠ¶è¡¨ç°æ¦‚ç‡
# =======================================================================

EMISSION_CPT = {
    'subjective_fatigue': {
        'low': {'Peak': 0.80, 'Well-adapted': 0.70, 'FOR': 0.25, 'Acute Fatigue': 0.05, 'NFOR': 0.05, 'OTS': 1e-6},
        'medium': {'Peak': 0.15, 'Well-adapted': 0.30, 'FOR': 0.20, 'Acute Fatigue': 0.15, 'NFOR': 0.10, 'OTS': 0.05},
        'high': {'Peak': 1e-6, 'Well-adapted': 1e-6, 'FOR': 0.70, 'Acute Fatigue': 0.80, 'NFOR': 0.80, 'OTS': 0.90}
    },
    "muscle_soreness": {
        "low": {"Peak": 0.80, "Well-adapted": 0.75, "FOR": 0.35, "Acute Fatigue": 0.10, "NFOR": 0.10, "OTS": 0.20},
        "medium": {"Peak": 0.10, "Well-adapted": 0.25, "FOR": 0.50, "Acute Fatigue": 0.30, "NFOR": 0.40, "OTS": 0.50},
        "high": {"Peak": 1e-6, "Well-adapted": 1e-6, "FOR": 0.35, "Acute Fatigue": 0.60, "NFOR": 0.50, "OTS": 0.30}
    },
    'subjective_stress': {
        'low': {'Peak': 0.80, 'Well-adapted': 0.70, 'FOR': 0.40, 'Acute Fatigue': 0.20, 'NFOR': 0.10, 'OTS': 1e-6},
        'medium': {'Peak': 0.10, 'Well-adapted': 0.30, 'FOR': 0.50, 'Acute Fatigue': 0.50, 'NFOR': 0.30, 'OTS': 0.20},
        'high': {'Peak': 1e-6, 'Well-adapted': 1e-6, 'FOR': 0.10, 'Acute Fatigue': 0.30, 'NFOR': 0.60, 'OTS': 0.80}
    },
    'subjective_sleep': {
        'good': {'Peak': 0.80, 'Well-adapted': 0.75, 'FOR': 0.30, 'Acute Fatigue': 0.40, 'NFOR': 0.15, 'OTS': 0.10},
        'medium': {'Peak': 0.15, 'Well-adapted': 0.25, 'FOR': 0.40, 'Acute Fatigue': 0.40, 'NFOR': 0.35, 'OTS': 0.20},
        'poor': {'Peak': 1e-6, 'Well-adapted': 1e-6, 'FOR': 0.15, 'Acute Fatigue': 0.20, 'NFOR': 0.65, 'OTS': 0.70}
    },
    'sleep_performance': {
        'good': {'Peak': 0.80, 'Well-adapted': 0.70, 'FOR': 0.25, 'Acute Fatigue': 0.35, 'NFOR': 0.20, 'OTS': 0.15},
        'medium': {'Peak': 0.20, 'Well-adapted': 0.30, 'FOR': 0.50, 'Acute Fatigue': 0.50, 'NFOR': 0.40, 'OTS': 0.35},
        'poor': {'Peak': 1e-6, 'Well-adapted': 1e-6, 'FOR': 0.25, 'Acute Fatigue': 0.15, 'NFOR': 0.40, 'OTS': 0.50}
    },
    'hrv_trend': {
        'rising': {'Peak': 0.85, 'Well-adapted': 0.20, 'FOR': 0.10, 'Acute Fatigue': 0.10, 'NFOR': 0.05, 'OTS': 0.01},
        'stable': {'Peak': 0.4, 'Well-adapted': 0.3, 'FOR': 0.20, 'Acute Fatigue': 0.20, 'NFOR': 0.10, 'OTS': 0.05},
        'slight_decline': {'Peak': 0.05, 'Well-adapted': 0.10, 'FOR': 0.30, 'Acute Fatigue': 0.30, 'NFOR': 0.15, 'OTS': 0.09},
        'significant_decline': {'Peak': 1e-6, 'Well-adapted': 1e-6, 'FOR': 0.40, 'Acute Fatigue': 0.40, 'NFOR': 0.70, 'OTS': 0.80}
    },
    'nutrition': {
        'adequate': {'Peak': 0.50, 'Well-adapted': 0.60, 'FOR': 0.50, 'Acute Fatigue': 0.70, 'NFOR': 0.40, 'OTS': 0.30},
        'inadequate_mild': {'Peak': 0.40, 'Well-adapted': 0.40, 'FOR': 0.45, 'Acute Fatigue': 0.40, 'NFOR': 0.50, 'OTS': 0.45},
        'inadequate_moderate': {'Peak': 0.30, 'Well-adapted': 0.35, 'FOR': 0.42, 'Acute Fatigue': 0.35, 'NFOR': 0.55, 'OTS': 0.60},
        'inadequate_severe': {'Peak': 0.10, 'Well-adapted': 0.15, 'FOR': 0.40, 'Acute Fatigue': 0.30, 'NFOR': 0.60, 'OTS': 0.70}
    },
    'restorative_sleep': {
        'high': {'Peak': 0.85, 'Well-adapted': 0.75, 'FOR': 0.30, 'Acute Fatigue': 0.20, 'NFOR': 0.05, 'OTS': 1e-6},
        'medium': {'Peak': 0.40, 'Well-adapted': 0.50, 'FOR': 0.40, 'Acute Fatigue': 0.35, 'NFOR': 0.25, 'OTS': 0.15},
        'low': {'Peak': 1e-6, 'Well-adapted': 0.10, 'FOR': 0.20, 'Acute Fatigue': 0.30, 'NFOR': 0.70, 'OTS': 0.80}
    },
    'gi_symptoms': {
        'none': {'Peak': 0.90, 'Well-adapted': 0.85, 'FOR': 0.80, 'Acute Fatigue': 0.70, 'NFOR': 0.50, 'OTS': 0.40},
        'mild': {'Peak': 0.05, 'Well-adapted': 0.10, 'FOR': 0.15, 'Acute Fatigue': 0.25, 'NFOR': 0.40, 'OTS': 0.40},
        'severe': {'Peak': 1e-6, 'Well-adapted': 1e-6, 'FOR': 0.05, 'Acute Fatigue': 0.05, 'NFOR': 0.10, 'OTS': 0.20}
    },
    
    # =======================================================================
    # â˜…â˜…â˜… æ–°å¢ Journal ç—‡çŠ¶å‘å°„æ¦‚ç‡ â˜…â˜…â˜…
    # =======================================================================
    
    # 1. ä»Šæ—¥æ˜¯å¦ç”Ÿç—… (is_sick: True)
    'is_sick': {
        True: {'Peak': 1e-9, 'Well-adapted': 1e-6, 'FOR': 0.05, 'Acute Fatigue': 0.40, 'NFOR': 0.80, 'OTS': 0.90}
    },

    # 2. ä»Šæ—¥æ˜¯å¦å—ä¼¤ (is_injured: True)
    'is_injured': {
        True: {'Peak': 1e-9, 'Well-adapted': 1e-6, 'FOR': 0.10, 'Acute Fatigue': 0.50, 'NFOR': 0.70, 'OTS': 0.60}
    },

    # 3. ä»Šæ—¥å‘ç”Ÿé‡å¤§å‹åŠ›äº‹ä»¶ (high_stress_event_today: True)
    'high_stress_event_today': {
        True: {'Peak': 0.05, 'Well-adapted': 0.15, 'FOR': 0.25, 'Acute Fatigue': 0.30, 'NFOR': 0.50, 'OTS': 0.40}
    },

    # 4. ä»Šæ—¥å®Œæˆå†¥æƒ³ (meditation_done_today: True)
    'meditation_done_today': {
        True: {'Peak': 0.55, 'Well-adapted': 0.50, 'FOR': 0.45, 'Acute Fatigue': 0.40, 'NFOR': 0.35, 'OTS': 0.30}
    }
}

# =======================================================================
# â˜…â˜…â˜… åŸºçº¿è½¬ç§»æ¦‚ç‡è¡¨ - ç”¨äºå…ˆéªŒæ¦‚ç‡è®¡ç®—åŸºç¡€ â˜…â˜…â˜…  
# P(Today | Yesterday) - çŠ¶æ€è‡ªç„¶è½¬ç§»æ¦‚ç‡ï¼Œæ— å¤–éƒ¨å½±å“æ—¶çš„åŸºç¡€è½¬ç§»
# =======================================================================

BASELINE_TRANSITION_CPT = {
    'Peak': {'Peak': 0.80, 'Well-adapted': 0.10, 'FOR': 0.05, 'Acute Fatigue': 1e-6, 'NFOR': 1e-6, 'OTS': 1e-6},
    'Well-adapted': {'Peak': 0.60, 'Well-adapted': 0.35, 'FOR': 0.05, 'Acute Fatigue': 1e-6, 'NFOR': 1e-6, 'OTS': 1e-6},
    'FOR': {'Peak': 0.05, 'Well-adapted': 0.40, 'FOR': 0.30, 'Acute Fatigue': 0.10, 'NFOR': 0.10, 'OTS': 0.05},
    'Acute Fatigue': {'Peak': 0.20, 'Well-adapted': 0.70, 'FOR': 0.10, 'Acute Fatigue': 1e-6, 'NFOR': 1e-6, 'OTS': 1e-6},
    'NFOR': {'Peak': 0.01, 'Well-adapted': 0.05, 'FOR': 0.10, 'Acute Fatigue': 0.05, 'NFOR': 0.70, 'OTS': 0.09},
    'OTS': {'Peak': 0.01, 'Well-adapted': 0.04, 'FOR': 0.10, 'Acute Fatigue': 0.05, 'NFOR': 0.30, 'OTS': 0.50}
}

# ç¡®ä¿æ¯è¡Œæ¦‚ç‡æ€»å’Œä¸º1
for state in BASELINE_TRANSITION_CPT:
    total = sum(BASELINE_TRANSITION_CPT[state].values())
    if total > 0:
        BASELINE_TRANSITION_CPT[state] = {s: p / total for s, p in BASELINE_TRANSITION_CPT[state].items()}

READINESS_WEIGHTS = {'Peak': 100, 'Well-adapted': 85, 'FOR': 60, 'Acute Fatigue': 50, 'NFOR': 30, 'OTS': 10}

EVIDENCE_WEIGHTS_FITNESS = {
    "hrv_trend": 1.0,
    "restorative_sleep": 0.95,
    "sleep_performance": 0.90,
    "subjective_fatigue": 0.75,
    "subjective_stress": 0.70,
    "muscle_soreness": 0.65,
    "subjective_sleep": 0.60,
    "nutrition": 0.60,
    "gi_symptoms": 0.50,
    "fatigue_3day_state": 0.85,
    # æ–°å¢Journalè¯æ®æƒé‡
    "is_sick": 1,                    # ç”Ÿç—…çŠ¶æ€ - é«˜æƒé‡
    "is_injured": 0.8,                 # å—ä¼¤çŠ¶æ€ - é«˜æƒé‡
    "high_stress_event_today": 0.6,    # ä»Šæ—¥é‡å¤§å‹åŠ›äº‹ä»¶
    "meditation_done_today": 0.5       # ä»Šæ—¥å†¥æƒ³å®Œæˆ - ç§¯æå› ç´ 
}

# =======================================================================
# â˜…â˜…â˜… äº¤äº’æ•ˆåº”æŒ‡çº¹åº“ - ç”¨äºåéªŒæ¦‚ç‡è®¡ç®— â˜…â˜…â˜…
# ç‰¹æ®Šç—‡çŠ¶ç»„åˆçš„å‘å°„æ¦‚ç‡ï¼ˆè‚Œè‚‰é…¸ç—› + ä¸»è§‚å‹åŠ›ï¼‰
# =======================================================================

INTERACTION_CPT_SORENESS_STRESS = {
    ("low", "high"): {"Peak": 1e-6, "Well-adapted": 0.05, "FOR": 0.15, "Acute Fatigue": 0.20, "NFOR": 0.60, "OTS": 0.50},
    ("low", "low"): {"Peak": 0.70, "Well-adapted": 0.60, "FOR": 0.20, "Acute Fatigue": 0.10, "NFOR": 0.05, "OTS": 1e-6},
    ("low", "medium"): {"Peak": 0.50, "Well-adapted": 0.45, "FOR": 0.30, "Acute Fatigue": 0.15, "NFOR": 0.10, "OTS": 0.05},
    ("medium", "low"): {"Peak": 0.40, "Well-adapted": 0.50, "FOR": 0.35, "Acute Fatigue": 0.20, "NFOR": 0.10, "OTS": 0.05},
    ("medium", "medium"): {"Peak": 0.25, "Well-adapted": 0.35, "FOR": 0.40, "Acute Fatigue": 0.30, "NFOR": 0.20, "OTS": 0.10},
    ("medium", "high"): {"Peak": 0.10, "Well-adapted": 0.15, "FOR": 0.25, "Acute Fatigue": 0.25, "NFOR": 0.45, "OTS": 0.30},
    ("high", "low"): {"Peak": 1e-6, "Well-adapted": 0.10, "FOR": 0.60, "Acute Fatigue": 0.50, "NFOR": 0.15, "OTS": 0.10},
    ("high", "medium"): {"Peak": 1e-6, "Well-adapted": 0.05, "FOR": 0.50, "Acute Fatigue": 0.60, "NFOR": 0.25, "OTS": 0.20},
    ("high", "high"): {"Peak": 1e-6, "Well-adapted": 1e-6, "FOR": 0.30, "Acute Fatigue": 0.40, "NFOR": 0.50, "OTS": 0.60}
}

# =======================================================================
# â˜…â˜…â˜… å…ˆéªŒæ¦‚ç‡å½±å“å› å­CPTè¡¨ - ç”¨äºå…ˆéªŒæ¦‚ç‡è®¡ç®— â˜…â˜…â˜…
# P(Today | Causal_Factor) - å„ç§åŸå› å¯¹ä»Šæ—¥çŠ¶æ€æ¦‚ç‡çš„å½±å“
# =======================================================================

# å¥åº·ä¸­æ€§åŸºçº¿ (ç”¨äºæ— å½±å“å› å­æ—¶)
HEALTHY_NEUTRAL_BASELINE = {'Peak': 1, 'Well-adapted': 1, 'FOR': 1, 'Acute Fatigue': 1, 'NFOR': 1, 'OTS': 1}

# åŸå› 1: é…’ç²¾æ‘„å…¥ (P(ä»Šæ—¥çŠ¶æ€ | æ˜¨æ™šæ˜¯å¦é¥®é…’))
ALCOHOL_CONSUMPTION_CPT = {
    # æŒ‰å»ºè®®ï¼šé¿å…ç»å¯¹0ï¼Œä½¿ç”¨æå°å€¼1e-6ä»¥å…¼å®¹ä¹˜æ³•æ›´æ–°ï¼›åŒæ—¶åŠ å¼ºå¯¹è‰¯å¥½çŠ¶æ€çš„æŠ‘åˆ¶
    True:  {'Peak': 1e-6, 'Well-adapted': 0.10, 'FOR': 0.20, 'Acute Fatigue': 0.40, 'NFOR': 0.30, 'OTS': 1e-6},
    False: HEALTHY_NEUTRAL_BASELINE # æœªæ‘„å…¥ï¼Œä½¿ç”¨ä¸­æ€§åŸºçº¿
}

# åŸå› 2: æ·±å¤œå’–å•¡å›  (P(ä»Šæ—¥çŠ¶æ€ | æ˜¨æ™šæ˜¯å¦æ‘„å…¥å’–å•¡å› ))
LATE_CAFFEINE_CPT = {
    # é¿å…ç»å¯¹0ï¼ˆOTSï¼‰ï¼Œæ”¹ä¸ºæå°å€¼
    True:  {'Peak': 0.10, 'Well-adapted': 0.20, 'FOR': 0.20, 'Acute Fatigue': 0.15, 'NFOR': 0.30, 'OTS': 1e-6},
    False: HEALTHY_NEUTRAL_BASELINE # æœªæ‘„å…¥ï¼Œä½¿ç”¨ä¸­æ€§åŸºçº¿
}

# åŸå› 3: ç¡å‰å±å¹• (P(ä»Šæ—¥çŠ¶æ€ | æ˜¨æ™šæ˜¯å¦ä½¿ç”¨))
SCREEN_BEFORE_BED_CPT = {
    # ç•¥åŠ å¼ºè´Ÿé¢å½±å“ï¼Œä¸”é¿å…ç»å¯¹0ï¼ˆOTSï¼‰
    True:  {'Peak': 0.10, 'Well-adapted': 0.20, 'FOR': 0.30, 'Acute Fatigue': 0.25, 'NFOR': 0.25, 'OTS': 1e-6},
    False: HEALTHY_NEUTRAL_BASELINE # æœªä½¿ç”¨ï¼Œä½¿ç”¨ä¸­æ€§åŸºçº¿
}

# åŸå› 4: æœˆç»å‘¨æœŸ (P(ä»Šæ—¥çŠ¶æ€ | æ˜¨æ—¥æœˆç»é˜¶æ®µ))
# **å®Œå…¨æ ¹æ®æ‚¨çš„ç ”ç©¶è¡¨æ ¼è¿›è¡Œé‡æ–°æ ¡å‡†**
MENSTRUAL_PHASE_CPT = {
    # é˜¶æ®µ1: æœˆç»æœŸ/åµæ³¡æœŸæ—©æœŸ (å¤© 1-6)
    # ç‰¹å¾: ç”Ÿç†æ½œåŠ›é«˜ä½†ç¡çœ å—æ‰°ä¸”æŸä¼¤é£é™©æé«˜ã€‚æ¦‚ç‡åˆ†å¸ƒåæ˜ è¿™ç§çŸ›ç›¾æ€§ã€‚
    'menstrual_early_follicular': {'Peak': 0.15, 'Well-adapted': 0.40, 'FOR': 0.20, 'Acute Fatigue': 0.15, 'NFOR': 0.10, 'OTS': 0.0},
    
    # é˜¶æ®µ2: åµæ³¡æœŸæ™šæœŸ/æ’åµæœŸ (å¤© 7-14)
    # ç‰¹å¾: èƒ½é‡å’Œè¿åŠ¨è¡¨ç°çš„å³°å€¼ã€‚æ¦‚ç‡åˆ†å¸ƒæ˜¾è‘—åå‘æœ€ä½³çŠ¶æ€ã€‚
    'late_follicular_ovulatory':  {'Peak': 0.45, 'Well-adapted': 0.45, 'FOR': 0.05, 'Acute Fatigue': 0.03, 'NFOR': 0.02, 'OTS': 0.0},

    # é˜¶æ®µ3: é»„ä½“æœŸæ—©æœŸ (å¤© 15-21)
    # ç‰¹å¾: HRVå¼€å§‹ä¸‹é™ï¼Œæ¢å¤å˜æ…¢ã€‚æ¦‚ç‡åˆ†å¸ƒå¼€å§‹å‘ç–²åŠ³çŠ¶æ€åç§»ã€‚
    'early_luteal':     {'Peak': 0.10, 'Well-adapted': 0.30, 'FOR': 0.25, 'Acute Fatigue': 0.20, 'NFOR': 0.15, 'OTS': 0.0},

    # é˜¶æ®µ4: é»„ä½“æœŸæ™šæœŸ (å¤© 22-28)
    # ç‰¹å¾: æ¢å¤æœ€å›°éš¾çš„æ—¶æœŸï¼ŒPMSç—‡çŠ¶ã€‚æ¦‚ç‡åˆ†å¸ƒæ˜¾è‘—åå‘æ¢å¤ä¸ä½³çš„çŠ¶æ€ã€‚
    # ä¿®æ­£ï¼šåŸè¡¨å„é¡¹ä¹‹å’Œâ‰ˆ1.13ï¼Œè¿™é‡ŒæŒ‰æ¯”ä¾‹ç¼©æ”¾è‡³æ€»å’Œâ‰ˆ1.0
    'late_luteal':     {'Peak': 0.044, 'Well-adapted': 0.177, 'FOR': 0.177, 'Acute Fatigue': 0.248, 'NFOR': 0.354, 'OTS': 0.0}
}

# å‰ä¸€å¤©çš„è®­ç»ƒè´Ÿè· (P(ä»Šæ—¥çŠ¶æ€ | æ˜¨æ—¥è®­ç»ƒè´Ÿè·))
TRAINING_LOAD_CPT = {
    'æé«˜': {'Peak': 0.01, 'Well-adapted': 0.05, 'FOR': 0.40, 'Acute Fatigue': 0.50, 'NFOR': 0.04, 'OTS': 0.0},
    'é«˜':   {'Peak': 0.05, 'Well-adapted': 0.15, 'FOR': 0.50, 'Acute Fatigue': 0.25, 'NFOR': 0.05, 'OTS': 0.0},
    'ä¸­':   {'Peak': 0.10, 'Well-adapted': 0.60, 'FOR': 0.20, 'Acute Fatigue': 0.08, 'NFOR': 0.02, 'OTS': 0.0},
    'ä½':   {'Peak': 0.20, 'Well-adapted': 0.70, 'FOR': 0.05, 'Acute Fatigue': 0.04, 'NFOR': 0.01, 'OTS': 0.0},
    'æ— ':   {'Peak': 0.30, 'Well-adapted': 0.60, 'FOR': 0.05, 'Acute Fatigue': 0.03, 'NFOR': 0.02, 'OTS': 0.0}
}

# ç¡å‰è¿›é£Ÿ (æ¡ä»¶æ€§) (P(ä»Šæ—¥çŠ¶æ€ | æ˜¨æ™šè¿›é£Ÿæƒ…å†µ))
LATE_MEAL_CPT = {
    # é™ä½â€œpositiveâ€å¯¹è‰¯å¥½çŠ¶æ€çš„è¿‡å¼ºæ‹‰å‡ï¼Œé¿å…æ©ç›–å¼ºè´Ÿé¢å› å­
    'positive': {'Peak': 0.50, 'Well-adapted': 0.50, 'FOR': 0.45, 'Acute Fatigue': 0.30, 'NFOR': 0.25, 'OTS': 1e-6},
    'negative': {'Peak': 0.20, 'Well-adapted': 0.20, 'FOR': 0.30, 'Acute Fatigue': 0.30, 'NFOR': 0.10, 'OTS': 1e-6},
    'neutral':  {'Peak': 0.30, 'Well-adapted': 0.50, 'FOR': 0.10, 'Acute Fatigue': 0.05, 'NFOR': 0.05, 'OTS': 1e-6}
}

# "åŸå› "æƒé‡è¡¨ (Causal Factor Weights)
CAUSAL_FACTOR_WEIGHTS = {
    'baseline_transition': 1.0, 
    'training_load': 1,
    'alcohol': 1.0,
    'menstrual_phase': 0.8,
    'late_meal': 0.5,
    'late_caffeine': 0.5,
    'screen_before_bed': 0.3
}

class JournalManager:
    """
    æ—¥å¿—ç®¡ç†å™¨ - è´Ÿè´£ç”¨æˆ·æ—¥å¿—æ•°æ®çš„ç®¡ç†å’Œå¤„ç†
    """
    
    def __init__(self):
        # æ¨¡æ‹Ÿæ—¥å¿—æ•°æ®åº“ï¼ˆå®é™…åº”ç”¨ä¸­è¿æ¥çœŸå®æ•°æ®åº“ï¼‰
        self.journal_database = {}
        
    def get_yesterdays_journal(self, user_id: str, today_date: str) -> Dict[str, Any]:
        """è·å–æ˜¨å¤©çš„æ—¥å¿—æ•°æ®ç”¨äºå½±å“ä»Šæ—¥å…ˆéªŒæ¦‚ç‡"""
        yesterday_date = self._get_previous_date(today_date)
        journal_key = f"{user_id}_{yesterday_date}"
        
        # è¿”å›æ˜¨å¤©çš„å®Œæ•´æ—¥å¿—æ•°æ®
        return self.journal_database.get(journal_key, {
            'short_term_behaviors': {},
            'persistent_status': {},
            'training_context': {}
        })
    
    def get_today_journal_evidence(self, user_id: str, date: str) -> Dict[str, Any]:
        """è·å–ä»Šå¤©å¯ä»¥ä½œä¸ºè¯æ®çš„æ—¥å¿—æ¡ç›®ï¼ˆå¦‚ç”Ÿç—…ã€çªå‘å‹åŠ›ï¼‰"""
        journal_key = f"{user_id}_{date}"
        today_journal = self.journal_database.get(journal_key, {})
        
        # åªè¿”å›å¯ä»¥ä½œä¸ºå½“å¤©è¯æ®çš„æ—¥å¿—æ¡ç›®
        evidence = {}
        persistent_status = today_journal.get('persistent_status', {})
        short_term = today_journal.get('short_term_behaviors', {})
        
        # æŒç»­çŠ¶æ€ç±»è¯æ®
        if persistent_status.get('is_sick'):
            evidence['is_sick'] = True
        if persistent_status.get('is_injured'):
            evidence['is_injured'] = True
        if persistent_status.get('high_stress_event_today'):
            evidence['high_stress_event_today'] = True
            
        # å½“å¤©è¡Œä¸ºç±»è¯æ®
        if short_term.get('meditation_done_today'):
            evidence['meditation_done_today'] = True
            
        return evidence
    
    def add_journal_entry(self, user_id: str, date: str, entry_type: str, entry_data: Dict):
        """æ·»åŠ æ—¥å¿—æ¡ç›®"""
        journal_key = f"{user_id}_{date}"
        if journal_key not in self.journal_database:
            self.journal_database[journal_key] = {
                'short_term_behaviors': {},
                'persistent_status': {},
                'training_context': {}
            }
        
        self.journal_database[journal_key][entry_type].update(entry_data)
    
    def auto_clear_short_term_flags(self, user_id: str, yesterday_date: str):
        """è‡ªåŠ¨æ¸…ç†æ˜¨å¤©çš„çŸ­æœŸè¡Œä¸ºæ ‡è®°ï¼ˆåœ¨è®¡ç®—å®Œå…ˆéªŒæ¦‚ç‡åï¼‰"""
        journal_key = f"{user_id}_{yesterday_date}"
        if journal_key in self.journal_database:
            # æ¸…ç©ºçŸ­æœŸè¡Œä¸ºï¼Œä¿ç•™æŒç»­çŠ¶æ€å’Œè®­ç»ƒä¸Šä¸‹æ–‡
            self.journal_database[journal_key]['short_term_behaviors'] = {}
            print(f"âœ“ å·²è‡ªåŠ¨æ¸…ç† {yesterday_date} çš„çŸ­æœŸè¡Œä¸ºæ ‡è®°")
    
    def _get_previous_date(self, date_str: str) -> str:
        """è·å–å‰ä¸€å¤©çš„æ—¥æœŸ"""
        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        previous_date = date_obj - timedelta(days=1)
        return previous_date.strftime("%Y-%m-%d")

class DailyReadinessManager:
    """
    åŠ¨æ€å‡†å¤‡åº¦ç®¡ç†å™¨ - æ ¸å¿ƒç±»
    è´Ÿè´£ç®¡ç†ä¸€æ•´å¤©çš„å‡†å¤‡åº¦è¯„ä¼°æµç¨‹
    """
    
    def __init__(self, user_id: str, date: str, previous_state_probs: Optional[Dict] = None, gender: str = 'ç”·æ€§'):
        """
        åˆå§‹åŒ–å½“å¤©çš„å‡†å¤‡åº¦ç®¡ç†å™¨
        
        Args:
            user_id: ç”¨æˆ·ID
            date: æ—¥æœŸ (YYYY-MM-DDæ ¼å¼)
            previous_state_probs: æ˜¨å¤©çš„æœ€ç»ˆçŠ¶æ€æ¦‚ç‡åˆ†å¸ƒ
            gender: ç”¨æˆ·æ€§åˆ« ('ç”·æ€§' æˆ– 'å¥³æ€§')
        """
        self.user_id = user_id
        self.date = date
        self.gender = gender
        self.states = ['Peak', 'Well-adapted', 'FOR', 'Acute Fatigue', 'NFOR', 'OTS']
        
        # åˆå§‹åŒ–æ˜¨å¤©çš„çŠ¶æ€æ¦‚ç‡ï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
        self.previous_probs = previous_state_probs or {
            'Peak': 0.3, 'Well-adapted': 0.5, 'FOR': 0.15, 
            'Acute Fatigue': 0.05, 'NFOR': 0.0, 'OTS': 0.0
        }
        
        # æ—¥å¿—ç®¡ç†å™¨
        self.journal_manager = JournalManager()
        
        # ä»Šæ—¥å…ˆéªŒæ¦‚ç‡ï¼ˆå›ºå®šï¼Œæ¯å¤©åªè®¡ç®—ä¸€æ¬¡ï¼‰
        self.today_prior_probs = None
        self.prior_calculated = False
        
        # ä»Šæ—¥åéªŒæ¦‚ç‡ï¼ˆåŠ¨æ€æ›´æ–°ï¼‰
        self.today_posterior_probs = None
        
        # è¯æ®æ± ï¼ˆç´¯ç§¯å½“å¤©æ”¶åˆ°çš„æ‰€æœ‰è¯æ®ï¼‰
        self.evidence_pool = {}
        
        # æ›´æ–°å†å²è®°å½•
        self.update_history = []
        
    def calculate_today_prior(self, causal_inputs: Dict[str, Any]) -> Dict[str, float]:
        """
        â˜…â˜…â˜… è®¡ç®—ä»Šæ—¥å…ˆéªŒæ¦‚ç‡ (PRIOR PROBABILITY) â˜…â˜…â˜…
        åŸºäºæ˜¨å¤©çŠ¶æ€ã€ä¼ ç»Ÿå› æœè¾“å…¥å’Œæ—¥å¿—å½±å“è®¡ç®—ä»Šæ—¥çš„é¢„æµ‹æ¦‚ç‡
        æ³¨æ„ï¼šæ­¤æ–¹æ³•æ¯å¤©åªèƒ½è°ƒç”¨ä¸€æ¬¡ï¼Œç»“æœå›ºå®šä¸å˜ï¼Œä½œä¸ºåç»­æ‰€æœ‰æ›´æ–°çš„åŸºç¡€
        
        è®¡ç®—æ­¥éª¤ï¼š
        1. BASELINE_TRANSITION_CPT: åŸºçº¿è½¬ç§»æ¦‚ç‡
        2. TRAINING_LOAD_CPTç­‰: ä¼ ç»Ÿå› æœè¾“å…¥å½±å“
        3. ALCOHOL_CONSUMPTION_CPTç­‰: æ—¥å¿—åŸå› å½±å“
        
        Args:
            causal_inputs: ä¼ ç»Ÿå› æœè¾“å…¥ï¼ˆè®­ç»ƒè´Ÿè·ã€ç¡çœ çŠ¶æ€ç­‰ï¼‰
            
        Returns:
            ä»Šæ—¥å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒ - P(Today_State | All_Causal_Factors)
        """
        if self.prior_calculated:
            return self.today_prior_probs
        
        print(f"å¼€å§‹è®¡ç®— {self.date} çš„å…ˆéªŒæ¦‚ç‡")
            
        # ç¬¬1æ­¥ï¼šä»åŸºçº¿è½¬ç§»æ¦‚ç‡å¼€å§‹
        prior_probs = {}
        for today_state in self.states:
            prior_probs[today_state] = sum(
                self.previous_probs.get(yesterday_state, 0) * 
                BASELINE_TRANSITION_CPT[yesterday_state].get(today_state, 1e-6)
                for yesterday_state in self.states
            )
        
        # æ ‡å‡†åŒ–
        total = sum(prior_probs.values())
        if total > 0:
            prior_probs = {state: prob / total for state, prob in prior_probs.items()}
        
        print("   åŸºçº¿è½¬ç§»æ¦‚ç‡è®¡ç®—å®Œæˆ")
        self._print_probabilities("åŸºçº¿è½¬ç§»å", prior_probs)
        
        # ç¬¬2æ­¥ï¼šåº”ç”¨ä¼ ç»Ÿå› æœè¾“å…¥å½±å“ï¼ˆå¤ç”¨CPT_test.pyé€»è¾‘ï¼‰
        prior_probs = self._apply_traditional_causal_inputs(prior_probs, causal_inputs)
        print("   ä¼ ç»Ÿå› æœè¾“å…¥å½±å“è®¡ç®—å®Œæˆ")
        self._print_probabilities("ä¼ ç»Ÿå› æœå", prior_probs)
        
        # ç¬¬3æ­¥ï¼šè·å–æ˜¨å¤©çš„æ—¥å¿—æ•°æ®å¹¶åº”ç”¨å½±å“
        yesterday_journal = self.journal_manager.get_yesterdays_journal(self.user_id, self.date)
        if yesterday_journal and any(yesterday_journal.values()):
            # ä¼ é€’è®­ç»ƒå¼ºåº¦ç»™ç¡å‰é¥®é£Ÿé€»è¾‘ä½¿ç”¨
            training_load = causal_inputs.get('training_load', 'æ— ')
            prior_probs = self._apply_journal_prior_impacts(prior_probs, yesterday_journal, training_load)
            print("   æ—¥å¿—å…ˆéªŒå½±å“è®¡ç®—å®Œæˆ")
            self._print_probabilities("æ—¥å¿—å½±å“å", prior_probs)
        else:
            print("   æ˜¨å¤©æ— æ—¥å¿—æ•°æ®ï¼Œè·³è¿‡æ—¥å¿—å…ˆéªŒå½±å“")
        
        # ç¬¬4æ­¥ï¼šè‡ªåŠ¨æ¸…ç†æ˜¨å¤©çš„çŸ­æœŸè¡Œä¸ºæ ‡è®°
        yesterday_date = self.journal_manager._get_previous_date(self.date)
        self.journal_manager.auto_clear_short_term_flags(self.user_id, yesterday_date)
        
        self.today_prior_probs = prior_probs
        self.today_posterior_probs = prior_probs.copy()  # åˆå§‹åŒ–åéªŒ=å…ˆéªŒ
        self.prior_calculated = True
        
        print(f"{self.date} å…ˆéªŒæ¦‚ç‡è®¡ç®—å®Œæˆ")
        self._print_probabilities("æœ€ç»ˆå…ˆéªŒ", self.today_prior_probs)
        
        return self.today_prior_probs
    
    def _apply_traditional_causal_inputs(self, probs: Dict[str, float], causal_inputs: Dict[str, Any]) -> Dict[str, float]:
        """
        åº”ç”¨ä¼ ç»Ÿå› æœè¾“å…¥çš„å½±å“ - ä½¿ç”¨æ–°çš„CPTè¡¨
        """
        adjusted_probs = probs.copy()
        
        # å¤„ç†è®­ç»ƒè´Ÿè·å½±å“
        if 'training_load' in causal_inputs:
            training_load = causal_inputs['training_load']
            if training_load in TRAINING_LOAD_CPT:
                print(f"     åº”ç”¨è®­ç»ƒè´Ÿè·å½±å“: {training_load}")
                training_impact = TRAINING_LOAD_CPT[training_load]
                weight = CAUSAL_FACTOR_WEIGHTS.get('training_load', 1.0)
                adjusted_probs = self._combine_probabilities_multiplicative(adjusted_probs, training_impact, weight)
        
        # è¿ç»­è®­ç»ƒæƒ©ç½šï¼ˆ4/8å¤©å†…é«˜å¼ºåº¦ä¸ä¼‘æ¯ï¼‰
        recent_loads = causal_inputs.get('recent_training_loads')
        if isinstance(recent_loads, list) and recent_loads:
            adjusted_probs = self._apply_training_streak_penalty(adjusted_probs, recent_loads)

        # TODO: å¯ä»¥æ·»åŠ å…¶ä»–ä¼ ç»Ÿå› æœè¾“å…¥å¦‚ç´¯ç§¯ç–²åŠ³ç­‰
        
        return adjusted_probs
        
    def _apply_training_streak_penalty(self, probs: Dict[str, float], recent_training_loads: List[str]) -> Dict[str, float]:
        """
        æ ¹æ®æœ€è¿‘è®­ç»ƒå¼ºåº¦åºåˆ—æ–½åŠ â€œè¿ç»­é«˜å¼ºåº¦ä¸ä¼‘æ¯â€çš„å…ˆéªŒæƒ©ç½šã€‚
        è§„åˆ™å‚è€ƒ CPT_testï¼š
        - æœ€è¿‘4å¤©ä¸­â€œé«˜/æé«˜â€å¤©æ•°>=3 â†’ ä»è‰¯å¥½/ä¸€èˆ¬/ç–²åŠ³çŠ¶æ€å‘ NFOR è¿ç§» 50%
        - æœ€è¿‘8å¤©ä¸­â€œé«˜/æé«˜â€å¤©æ•°>=6 â†’ å†å‘ NFOR è¿ç§» 60%
        ä¸¤æ¡è§„åˆ™æŒ‰é¡ºåºå åŠ ï¼ˆæ¯æ¬¡éƒ½ä¼šå½’ä¸€åŒ–ï¼‰ã€‚
        """
        adjusted = probs.copy()
        HIGH = {'é«˜', 'æé«˜'}
        loads = list(recent_training_loads or [])
        # è¿‘4å¤©
        if len(loads) >= 4:
            last4 = loads[-4:]
            if sum(1 for x in last4 if x in HIGH) >= 3:
                print("     è¿ç»­è®­ç»ƒæƒ©ç½š: æœ€è¿‘4å¤©é«˜å¼ºåº¦â‰¥3æ¬¡ â†’ å‘NFORè¿ç§»50%")
                adjusted = self._shift_probability(adjusted, ['Peak', 'Well-adapted', 'FOR', 'Acute Fatigue'], ['NFOR'], 0.50)
        # è¿‘8å¤©
        if len(loads) >= 8:
            last8 = loads[-8:]
            if sum(1 for x in last8 if x in HIGH) >= 6:
                print("     è¿ç»­è®­ç»ƒæƒ©ç½š: æœ€è¿‘8å¤©é«˜å¼ºåº¦â‰¥6æ¬¡ â†’ å‘NFORè¿ç§»60%")
                adjusted = self._shift_probability(adjusted, ['Peak', 'Well-adapted', 'FOR', 'Acute Fatigue'], ['NFOR'], 0.60)
        return adjusted
    def _apply_journal_prior_impacts(self, probs: Dict[str, float], journal_data: Dict[str, Any], training_load: str = 'æ— ') -> Dict[str, float]:
        """
        åº”ç”¨æ—¥å¿—å¯¹å…ˆéªŒæ¦‚ç‡çš„å½±å“ - ä½¿ç”¨æ–°çš„CPTè¡¨
        æ³¨æ„ï¼šè¿™é‡Œåªå¤„ç†å½±å“ç¬¬äºŒå¤©çš„æ—¥å¿—æ¡ç›®
        """
        adjusted_probs = probs.copy()
        
        # å¤„ç†çŸ­æœŸè¡Œä¸ºçš„å…ˆéªŒå½±å“
        short_term = journal_data.get('short_term_behaviors', {})
        
        # é…’ç²¾æ‘„å…¥çš„å½±å“
        if short_term.get('alcohol_consumed'):
            print("     åº”ç”¨é…’ç²¾æ‘„å…¥å½±å“")
            alcohol_impact = ALCOHOL_CONSUMPTION_CPT[True]
            weight = CAUSAL_FACTOR_WEIGHTS.get('alcohol', 1.0)
            adjusted_probs = self._combine_probabilities_multiplicative(adjusted_probs, alcohol_impact, weight)
        
        # æ·±å¤œå’–å•¡å› çš„å½±å“
        if short_term.get('late_caffeine'):
            print("     åº”ç”¨æ·±å¤œå’–å•¡å› å½±å“")
            caffeine_impact = LATE_CAFFEINE_CPT[True]
            weight = CAUSAL_FACTOR_WEIGHTS.get('late_caffeine', 1.0)
            adjusted_probs = self._combine_probabilities_multiplicative(adjusted_probs, caffeine_impact, weight)
        
        # ç¡å‰å±å¹•ä½¿ç”¨çš„å½±å“
        if short_term.get('screen_before_bed'):
            print("     åº”ç”¨ç¡å‰å±å¹•å½±å“")
            screen_impact = SCREEN_BEFORE_BED_CPT[True]
            weight = CAUSAL_FACTOR_WEIGHTS.get('screen_before_bed', 1.0)
            adjusted_probs = self._combine_probabilities_multiplicative(adjusted_probs, screen_impact, weight)
        
        # ç¡å‰è¿›é£Ÿçš„å½±å“ - æ ¹æ®è®­ç»ƒå¼ºåº¦è‡ªåŠ¨å†³å®špositive/negative
        if short_term.get('late_meal'):  # late_meal = Trueæ—¶æ‰åº”ç”¨å½±å“
            # æ ¹æ®è®­ç»ƒå¼ºåº¦å†³å®šä½¿ç”¨positiveè¿˜æ˜¯negativeå½±å“
            if training_load in ['ä¸­', 'é«˜', 'æé«˜']:
                meal_status = 'positive'  # è®­ç»ƒå¼ºåº¦ä¸­ç­‰ä»¥ä¸Šï¼Œç¡å‰è¿›é£Ÿæ˜¯å¥½çš„
            else:
                meal_status = 'negative'  # è®­ç»ƒå¼ºåº¦ä½æˆ–æ— ï¼Œç¡å‰è¿›é£Ÿæ˜¯ä¸å¥½çš„
            
            print(f"     åº”ç”¨ç¡å‰è¿›é£Ÿå½±å“: {meal_status} (åŸºäºè®­ç»ƒå¼ºåº¦: {training_load})")
            meal_impact = LATE_MEAL_CPT[meal_status]
            weight = CAUSAL_FACTOR_WEIGHTS.get('late_meal', 1.0)
            adjusted_probs = self._combine_probabilities_multiplicative(adjusted_probs, meal_impact, weight)
            
        # å¤„ç†æŒç»­çŠ¶æ€çš„å…ˆéªŒå½±å“ - è¿™äº›æŒç»­çŠ¶æ€ä¹Ÿä¼šå½±å“ç¬¬äºŒå¤©
        persistent = journal_data.get('persistent_status', {})
        
        # ç”Ÿç—…çŠ¶æ€æŒç»­å½±å“ï¼ˆå¦‚æœæ˜¨å¤©ç”Ÿç—…ï¼Œä»Šå¤©å…ˆéªŒæ¦‚ç‡å—å½±å“ï¼‰
        if persistent.get('is_sick'):
            print("     åº”ç”¨æŒç»­ç”Ÿç—…çŠ¶æ€çš„å…ˆéªŒå½±å“")
            # è¿™é‡Œå¯ä»¥å®šä¹‰ç”Ÿç—…å¯¹ç¬¬äºŒå¤©å…ˆéªŒæ¦‚ç‡çš„å½±å“ï¼ˆä¸å½“å¤©è¯æ®å½±å“ä¸åŒï¼‰
            adjusted_probs = self._shift_probability(adjusted_probs, ['Peak', 'Well-adapted'], ['NFOR', 'OTS'], 0.4)
        
        # æŒç»­å—ä¼¤çš„å…ˆéªŒå½±å“ï¼šå°†éƒ¨åˆ†æ¦‚ç‡ä»è‰¯å¥½çŠ¶æ€è½¬ç§»åˆ°ç–²åŠ³/ä¸è‰¯çŠ¶æ€
        if persistent.get('is_injured'):
            print("     åº”ç”¨æŒç»­å—ä¼¤çŠ¶æ€çš„å…ˆéªŒå½±å“")
            adjusted_probs = self._shift_probability(adjusted_probs, ['Peak', 'Well-adapted'], ['FOR', 'NFOR'], 0.3)
        
        # æœˆç»å‘¨æœŸçš„å½±å“ï¼ˆä»…å¥³æ€§ä¸”æœ‰è®°å½•æ—¶ï¼‰
        if self.gender == 'å¥³æ€§' and 'menstrual_phase' in persistent:
            phase = persistent['menstrual_phase']
            if phase in MENSTRUAL_PHASE_CPT:
                print(f"     åº”ç”¨æœˆç»å‘¨æœŸå½±å“: {phase}")
                menstrual_impact = MENSTRUAL_PHASE_CPT[phase]
                weight = CAUSAL_FACTOR_WEIGHTS.get('menstrual_phase', 1.0)
                adjusted_probs = self._combine_probabilities_multiplicative(adjusted_probs, menstrual_impact, weight)
        elif self.gender == 'ç”·æ€§' and 'menstrual_phase' in persistent:
            print(f"     ç”·æ€§ç”¨æˆ·ï¼Œå¿½ç•¥æœˆç»å‘¨æœŸæ•°æ®: {persistent['menstrual_phase']}")
            
        return adjusted_probs
    
    def _combine_probabilities_weighted(self, current_probs: Dict[str, float], impact_cpt: Dict[str, float], weight: float) -> Dict[str, float]:
        """
        åŠ æƒæ¦‚ç‡ç»„åˆæ–¹æ³•ï¼šå°†å½“å‰æ¦‚ç‡åˆ†å¸ƒä¸CPTå½±å“è¿›è¡ŒåŠ æƒç»„åˆ
        
        Args:
            current_probs: å½“å‰çš„æ¦‚ç‡åˆ†å¸ƒ
            impact_cpt: CPTå½±å“æ¦‚ç‡åˆ†å¸ƒ
            weight: å½±å“æƒé‡ï¼ˆæ”¯æŒå¤§äº1çš„å€¼ï¼‰
            
        Returns:
            ç»„åˆåçš„æ¦‚ç‡åˆ†å¸ƒ
        """
        combined_probs = {}
        
        # æ ‡å‡†åŒ–æƒé‡ä»¥é¿å…è´Ÿæ¦‚ç‡
        # å¦‚æœweight > 1ï¼Œæˆ‘ä»¬å¢å¼ºCPTçš„å½±å“
        normalized_weight = min(weight, 1.0)  # é™åˆ¶åœ¨[0,1]èŒƒå›´å†…ç”¨äºæ’å€¼
        enhancement_factor = weight  # ä¿ç•™åŸå§‹æƒé‡ç”¨äºåç»­å¢å¼º
        
        # å¯¹æ¯ä¸ªçŠ¶æ€è¿›è¡ŒåŠ æƒç»„åˆ
        for state in self.states:
            current_prob = current_probs.get(state, 0)
            impact_prob = impact_cpt.get(state, 0)
            
            # åŸºç¡€æ’å€¼ç»„åˆ: (1-normalized_weight) * current + normalized_weight * impact
            base_combined = (1 - normalized_weight) * current_prob + normalized_weight * impact_prob
            
            # å¦‚æœåŸå§‹æƒé‡>1ï¼Œåˆ™å¢å¼ºCPTçš„å½±å“
            if weight > 1.0:
                enhancement = (weight - 1.0) * impact_prob
                combined_prob = base_combined + enhancement * 0.5  # é€‚åº¦å¢å¼ºé¿å…è¿‡åº¦å½±å“
            else:
                combined_prob = base_combined
                
            combined_probs[state] = max(1e-9, combined_prob)  # ç¡®ä¿éè´Ÿ
        
        # é‡æ–°æ ‡å‡†åŒ–ç¡®ä¿æ¦‚ç‡æ€»å’Œä¸º1
        total = sum(combined_probs.values())
        if total > 0:
            combined_probs = {state: prob / total for state, prob in combined_probs.items()}
        
        return combined_probs
    
    def _shift_probability(self, probs: Dict[str, float], from_states: List[str], to_states: List[str], shift_ratio: float) -> Dict[str, float]:
        """
        æ¦‚ç‡è½¬ç§»è¾…åŠ©å‡½æ•°ï¼šä»æŸäº›çŠ¶æ€è½¬ç§»æ¦‚ç‡åˆ°å…¶ä»–çŠ¶æ€
        """
        adjusted_probs = probs.copy()
        
        # è®¡ç®—éœ€è¦è½¬ç§»çš„æ€»æ¦‚ç‡é‡
        total_from_prob = sum(adjusted_probs.get(state, 0) for state in from_states)
        shift_amount = total_from_prob * shift_ratio
        
        # ä»æºçŠ¶æ€å‡å°‘æ¦‚ç‡
        for state in from_states:
            if state in adjusted_probs:
                reduction = (adjusted_probs[state] / total_from_prob) * shift_amount if total_from_prob > 0 else 0
                adjusted_probs[state] = max(1e-6, adjusted_probs[state] - reduction)
        
        # å‘ç›®æ ‡çŠ¶æ€å¢åŠ æ¦‚ç‡
        per_target_increase = shift_amount / len(to_states)
        for state in to_states:
            adjusted_probs[state] = adjusted_probs.get(state, 0) + per_target_increase
            
        # é‡æ–°æ ‡å‡†åŒ–
        total = sum(adjusted_probs.values())
        if total > 0:
            adjusted_probs = {state: prob / total for state, prob in adjusted_probs.items()}
            
        return adjusted_probs
    
    def _normalize_distribution(self, impact_cpt: Dict[str, float]) -> Dict[str, float]:
        """å°†å› å­å½±å“åˆ†å¸ƒè§„èŒƒåŒ–ä¸ºåˆæ³•æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶å¯¹é›¶å€¼åº”ç”¨æœ€å°ä¸‹é™ä»¥é¿å…ä¹˜æ³•å½’é›¶ã€‚"""
        eps = 1e-6
        clipped = {state: max(float(impact_cpt.get(state, eps)), eps) for state in self.states}
        total = sum(clipped.values())
        if total <= 0:
            return {s: 1.0 / len(self.states) for s in self.states}
        return {s: v / total for s, v in clipped.items()}

    def _combine_probabilities_multiplicative(self, current_probs: Dict[str, float], impact_cpt: Dict[str, float], weight: float) -> Dict[str, float]:
        """
        æŒ‰å»ºè®®å®ç°çš„ä¹˜æ³•ï¼ˆè´å¶æ–¯å¼ï¼‰ç»„åˆï¼š
        P'(state) âˆ P(state) * (impact_cpt[state]_clipped) ^ weight
        - ä»…å¯¹å•ä¸ªå€¼åšæœ€å°ä¸‹é™è£å‰ª max(x, 1e-6)ï¼Œä¸å¼ºåˆ¶å½’ä¸€åŒ– impact_cptã€‚
        - æ¯æ¬¡ç»„åˆåå½’ä¸€åŒ–è¾“å‡ºåˆ†å¸ƒã€‚
        """
        w = float(weight) if weight is not None else 1.0
        new_probs: Dict[str, float] = {}
        for state, curr_prob in current_probs.items():
            like = max(float(impact_cpt.get(state, 1e-6)), 1e-6)
            new_probs[state] = curr_prob * (like ** w)
        total = sum(new_probs.values())
        return {s: (p / total if total > 0 else 0.0) for s, p in new_probs.items()}

    def add_evidence_and_update(self, new_evidence: Dict[str, Any]) -> Dict[str, Any]:
        """
        â˜…â˜…â˜… æ›´æ–°åéªŒæ¦‚ç‡ (POSTERIOR PROBABILITY) â˜…â˜…â˜…
        åŸºäºå›ºå®šçš„å…ˆéªŒæ¦‚ç‡å’Œç´¯ç§¯çš„è¯æ®ï¼Œä½¿ç”¨æŒ‡çº¹åº“è®¡ç®—åéªŒæ¦‚ç‡
        è¿™æ˜¯æ ¸å¿ƒçš„å®æ—¶æ›´æ–°æ–¹æ³•ï¼Œå¯ä»¥è¢«å¤šæ¬¡è°ƒç”¨
        
        ä½¿ç”¨çš„æŒ‡çº¹åº“ï¼š
        1. EMISSION_CPT: ä¸»è¦ç—‡çŠ¶æŒ‡çº¹åº“
        2. INTERACTION_CPT_SORENESS_STRESS: äº¤äº’æ•ˆåº”æŒ‡çº¹åº“
        
        è¯æ®ä¼˜å…ˆçº§ï¼š
        1. Hooper Indexï¼ˆæœ€é‡è¦ä¸»è§‚æŒ‡æ ‡ï¼‰
        2. å®¢è§‚ç¡çœ /HRVæ•°æ®
        3. å°‘æ•°å½“å¤©Journalè¯æ®ï¼ˆå¦‚ç”Ÿç—…ã€çªå‘å‹åŠ›ï¼‰
        
        è®¡ç®—å…¬å¼: P(State | Evidence) âˆ P(State | Causal) Ã— P(Evidence | State)
                 å…ˆéªŒæ¦‚ç‡ Ã— æŒ‡çº¹åº“æ¦‚ç‡ = åéªŒæ¦‚ç‡
        
        Args:
            new_evidence: æ–°çš„è¯æ® {'fatigue_hooper': 4, 'hrv_trend': 'stable', 'is_sick': True}
            
        Returns:
            æ›´æ–°ç»“æœåŒ…å«å‡†å¤‡åº¦åˆ†æ•°å’Œæ¦‚ç‡åˆ†å¸ƒ
        """
        if not self.prior_calculated:
            raise RuntimeError("å¿…é¡»å…ˆè°ƒç”¨ calculate_today_prior() è®¡ç®—å…ˆéªŒæ¦‚ç‡")
        
        # æ›´æ–°è¯æ®æ±  - æ·»åŠ æ–°è¯æ®
        for key, value in new_evidence.items():
            if value is not None:  # åªæ·»åŠ éç©ºè¯æ®
                self.evidence_pool[key] = value
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»Šå¤©çš„Journalè¯æ®éœ€è¦æ·»åŠ 
        today_journal_evidence = self.journal_manager.get_today_journal_evidence(self.user_id, self.date)
        if today_journal_evidence:
            print(f"   æ£€æµ‹åˆ°å½“å¤©Journalè¯æ®: {today_journal_evidence}")
            self.evidence_pool.update(today_journal_evidence)
        
        # æ˜¾ç¤ºå½“å‰è¯æ®æ± çŠ¶æ€
        evidence_types = self._categorize_evidence(self.evidence_pool)
        print(f"å½“å‰è¯æ®æ± çŠ¶æ€:")
        for category, evidence_list in evidence_types.items():
            if evidence_list:
                print(f"   {category}: {evidence_list}")
        
        # ä½¿ç”¨å›ºå®šçš„å…ˆéªŒæ¦‚ç‡å’Œå®Œæ•´çš„è¯æ®æ± è®¡ç®—æ–°çš„åéªŒæ¦‚ç‡
        # é‡è¦ï¼šè¿™é‡Œå¤ç”¨CPT_test.pyçš„è´å¶æ–¯æ›´æ–°é€»è¾‘
        mapped_evidence = map_inputs_to_states(self.evidence_pool)
        self.today_posterior_probs = self._run_bayesian_update(
            self.today_prior_probs,  # å›ºå®šå…ˆéªŒ
            mapped_evidence         # ç´¯ç§¯çš„æ‰€æœ‰è¯æ®
        )
        
        # è®¡ç®—å‡†å¤‡åº¦åˆ†æ•°
        readiness_score = self._get_readiness_score(self.today_posterior_probs)
        
        # è®°å½•æ›´æ–°å†å²
        update_record = {
            'timestamp': datetime.now().isoformat(),
            'new_evidence': new_evidence.copy(),
            'evidence_pool_size': len(self.evidence_pool),
            'readiness_score': readiness_score,
            'posterior_probs': self.today_posterior_probs.copy()
        }
        self.update_history.append(update_record)
        
        # æ˜¾ç¤ºæ›´æ–°ç»“æœ
        diagnosis = max(self.today_posterior_probs, key=self.today_posterior_probs.get)
        print(f"å‡†å¤‡åº¦æ›´æ–°å®Œæˆ")
        print(f"   åˆ†æ•°: {readiness_score}/100 | è¯Šæ–­: {diagnosis}")
        print(f"   æ–°å¢è¯æ®: {list(new_evidence.keys())}")
        print(f"   ç´¯ç§¯è¯æ®: {len(self.evidence_pool)}é¡¹")
        
        return {
            'readiness_score': readiness_score,
            'diagnosis': diagnosis,
            'posterior_probs': self.today_posterior_probs,
            'evidence_pool_size': len(self.evidence_pool),
            'update_count': len(self.update_history)
        }
    
    def _categorize_evidence(self, evidence_pool: Dict[str, Any]) -> Dict[str, List[str]]:
        """å°†è¯æ®æŒ‰ç±»å‹åˆ†ç±»æ˜¾ç¤º"""
        hooper_evidence = []
        objective_evidence = []
        journal_evidence = []
        other_evidence = []
        
        for key in evidence_pool.keys():
            if 'hooper' in key:
                hooper_evidence.append(key)
            elif key in ['sleep_performance_state', 'hrv_trend', 'restorative_sleep']:
                objective_evidence.append(key)
            elif key in ['is_sick', 'is_injured', 'high_stress_event_today', 'meditation_done_today']:
                journal_evidence.append(key)
            else:
                other_evidence.append(key)
        
        return {
            'HooperæŒ‡æ•°': hooper_evidence,
            'å®¢è§‚æ•°æ®': objective_evidence, 
            'Journalè¯æ®': journal_evidence,
            'å…¶ä»–è¯æ®': other_evidence
        }
    
    def _run_bayesian_update(self, prior_probs: Dict, evidence: Dict) -> Dict[str, float]:
        """
        â˜…â˜…â˜… è´å¶æ–¯æ›´æ–°æ ¸å¿ƒç®—æ³• - æŒ‡çº¹åº“åŒ¹é… â˜…â˜…â˜…
        ä½¿ç”¨EMISSION_CPTæŒ‡çº¹åº“å’ŒINTERACTION_CPTè®¡ç®—ä¼¼ç„¶æ¦‚ç‡
        ï¼ˆä»CPT_test.pyç»§æ‰¿å¹¶é€‚é…ï¼‰
        
        æ ¸å¿ƒå…¬å¼: P(State | Evidence) = P(State) Ã— âˆP(Evidence_i | State)
        """
        posterior_probs = prior_probs.copy()
        weights = EVIDENCE_WEIGHTS_FITNESS
        
        # å¤„ç†è‚Œè‚‰é…¸ç—›+å‹åŠ›çš„äº¤äº’æ•ˆåº”
        interaction_processed = False
        if ("muscle_soreness" in evidence and evidence["muscle_soreness"] is not None and
            "subjective_stress" in evidence and evidence["subjective_stress"] is not None):
            
            muscle_val = evidence["muscle_soreness"]
            stress_val = evidence["subjective_stress"]
            interaction_key = (muscle_val, stress_val)
            
            if interaction_key in INTERACTION_CPT_SORENESS_STRESS:
                weight = weights.get("soreness_stress_interaction", 1.0)
                for state in self.states:
                    likelihood = INTERACTION_CPT_SORENESS_STRESS[interaction_key].get(state, 1e-6)
                    posterior_probs[state] *= (likelihood ** weight)
                interaction_processed = True
        
        # å¤„ç†å…¶ä»–ç‹¬ç«‹è¯æ®
        for evidence_type, value in evidence.items():
            if interaction_processed and evidence_type in ["muscle_soreness", "subjective_stress"]:
                continue
                
            if evidence_type in EMISSION_CPT and value is not None:
                for state in self.states:
                    likelihood = EMISSION_CPT[evidence_type].get(value, {}).get(state, 0.001)
                    weight = weights.get(evidence_type, 1.0)
                    posterior_probs[state] *= (likelihood ** weight)
        
        # æ ‡å‡†åŒ–
        total = sum(posterior_probs.values())
        if total > 0:
            posterior_probs = {state: prob / total for state, prob in posterior_probs.items()}
        
        return posterior_probs
    
    def _get_readiness_score(self, probs: Dict[str, float]) -> int:
        """è®¡ç®—å‡†å¤‡åº¦åˆ†æ•°ï¼ˆ0-100ï¼‰"""
        score = sum(probs.get(state, 0) * weight for state, weight in READINESS_WEIGHTS.items())
        return int(round(score))
    
    def _print_probabilities(self, title: str, probs: Dict[str, float]):
        """æ ¼å¼åŒ–æ‰“å°æ¦‚ç‡åˆ†å¸ƒ"""
        print(f"   {title}: " + " | ".join([f"{state}: {prob:.3f}" for state, prob in probs.items()]))
    
    def get_daily_summary(self) -> Dict[str, Any]:
        """è·å–å½“å¤©çš„å®Œæ•´æ€»ç»“"""
        if not self.today_posterior_probs:
            return {"error": "å°šæœªè¿›è¡Œä»»ä½•æ¦‚ç‡è®¡ç®—"}
        
        final_diagnosis = max(self.today_posterior_probs, key=self.today_posterior_probs.get)
        final_score = self._get_readiness_score(self.today_posterior_probs)
        
        return {
            'user_id': self.user_id,
            'date': self.date,
            'final_readiness_score': final_score,
            'final_diagnosis': final_diagnosis,
            'final_posterior_probs': self.today_posterior_probs,
            'prior_probs': self.today_prior_probs,
            'evidence_pool': self.evidence_pool,
            'total_updates': len(self.update_history),
            'update_history': self.update_history
        }


def map_inputs_to_states(raw_inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    å°†åŸå§‹è¾“å…¥æ˜ å°„åˆ°æ¨¡å‹çŠ¶æ€ï¼ˆä»CPT_test.pyç»§æ‰¿ï¼‰
    """
    mapped = {}
    
    # Hooperé‡è¡¨æ˜ å°„ (1-7 -> low/medium/high)
    hooper_mapping = {
        'fatigue_hooper': 'subjective_fatigue',
        'soreness_hooper': 'muscle_soreness', 
        'stress_hooper': 'subjective_stress',
        'sleep_hooper': 'subjective_sleep'
    }
    
    for raw_key, model_key in hooper_mapping.items():
        if raw_key in raw_inputs:
            val = raw_inputs[raw_key]
            if val is not None and 1 <= val <= 7:
                if val <= 2:
                    mapped[model_key] = 'low'
                elif val <= 4:
                    mapped[model_key] = 'medium'
                else:
                    mapped[model_key] = 'high'
    
    # ç›´æ¥æ˜ å°„çš„å­—æ®µ
    direct_mappings = [
        'sleep_performance_state', 'restorative_sleep', 'hrv_trend', 
        'nutrition', 'gi_symptoms', 'fatigue_3day_state'
    ]
    
    for key in direct_mappings:
        if key in raw_inputs and raw_inputs[key] is not None:
            mapped[key.replace('_state', '')] = raw_inputs[key]
    
    # ç›´æ¥ä¿ç•™ä½œä¸ºå‘å°„è¯æ®ä½¿ç”¨çš„å¸ƒå°”Journalé”®
    for key in ['is_sick', 'is_injured', 'high_stress_event_today', 'meditation_done_today']:
        if key in raw_inputs and raw_inputs[key] is not None:
            mapped[key] = raw_inputs[key]
    
    return mapped


if __name__ == "__main__":
    """
    æ¨¡æ‹ŸçœŸå®ä½¿ç”¨åœºæ™¯çš„åŠ¨æ€å‡†å¤‡åº¦è¯„ä¼°æµç¨‹
    æŒ‰ç…§å®é™…çš„æ—¶é—´é¡ºåºå’Œæ•°æ®è¾“å…¥æµç¨‹
    """
    print("ğŸƒ åŠ¨æ€å‡†å¤‡åº¦æ¨¡å‹ v2.0 - çœŸå®ä½¿ç”¨åœºæ™¯æ¨¡æ‹Ÿ")
    print("="*70)
    
    # =================== å‡†å¤‡é˜¶æ®µï¼šè®¾ç½®æ¨¡æ‹Ÿæ•°æ® ===================
    print("\nğŸ“‹ å‡†å¤‡é˜¶æ®µï¼šè®¾ç½®æ¨¡æ‹Ÿçš„æ—¥å¿—æ•°æ®")
    print("-"*50)
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = DailyReadinessManager(
        user_id="athlete_001", 
        date="2024-01-16",
        previous_state_probs={'Peak': 0.15, 'Well-adapted': 0.60, 'FOR': 0.20, 'Acute Fatigue': 0.05, 'NFOR': 0.0, 'OTS': 0.0}
    )
    
    # æ¨¡æ‹Ÿæ·»åŠ æ˜¨å¤©çš„æ—¥å¿—æ•°æ®
    manager.journal_manager.add_journal_entry("athlete_001", "2024-01-15", "short_term_behaviors", {
        'alcohol_consumed': True,    # æ˜¨æ™šå–äº†é…’
        'ate_before_bed': False,     # æ²¡æœ‰ç¡å‰è¿›é£Ÿ
        'stayed_up_late': False      # æ²¡æœ‰ç†¬å¤œ
    })
    
    manager.journal_manager.add_journal_entry("athlete_001", "2024-01-15", "persistent_status", {
        'is_sick': False,            # æ²¡æœ‰ç”Ÿç—…
        'high_work_stress_period': True  # å·¥ä½œå‹åŠ›æœŸ
    })
    
    manager.journal_manager.add_journal_entry("athlete_001", "2024-01-15", "training_context", {
        'training_load': 'é«˜',       # æ˜¨å¤©é«˜å¼ºåº¦è®­ç»ƒ
        'cumulative_fatigue_14day': 'medium'
    })
    
    # æ¨¡æ‹Ÿä»Šå¤©çªç„¶ç”Ÿç—…
    manager.journal_manager.add_journal_entry("athlete_001", "2024-01-16", "persistent_status", {
        'is_sick': True,             # ä»Šå¤©æ„Ÿè§‰ç”Ÿç—…äº†
        'acute_stress': None
    })
    
    print("âœ… æ¨¡æ‹Ÿæ•°æ®è®¾ç½®å®Œæˆ")
    
    # =================== ç¬¬1æ­¥ï¼šè®¡ç®—ä»Šæ—¥å…ˆéªŒæ¦‚ç‡ ===================
    print(f"\nğŸ§  ç¬¬1æ­¥ï¼šåŸºäºæ˜¨å¤©æ•°æ®è®¡ç®—ä»Šæ—¥å…ˆéªŒæ¦‚ç‡")
    print("-"*50)
    print("â° æ—¶é—´ï¼šä»Šæ—©7:00ï¼ˆç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œï¼‰")
    
    # ä¼ ç»Ÿå› æœè¾“å…¥
    causal_inputs = {
        'training_load': 'é«˜',  # æ˜¨å¤©è®­ç»ƒå¼ºåº¦
        'subjective_sleep_state': 'good',  # æ˜¨æ™šç¡çœ çŠ¶æ€
        'cumulative_fatigue_14day_state': 'medium'  # ç´¯ç§¯ç–²åŠ³
    }
    
    prior = manager.calculate_today_prior(causal_inputs)
    
    # =================== ç¬¬2æ­¥ï¼šæ—©ä¸Šç¡çœ +HRVæ•°æ®æ›´æ–° ===================
    print(f"\nâ˜€ï¸ ç¬¬2æ­¥ï¼šæ—©ä¸Šç¡çœ å’ŒHRVæ•°æ®æ›´æ–°")
    print("-"*50)
    print("â° æ—¶é—´ï¼šä»Šæ—©8:00")
    print("ğŸ“± è‡ªåŠ¨åŒæ­¥æ˜¨æ™šçš„ç¡çœ ä¼ æ„Ÿå™¨å’ŒHRVæ•°æ®")
    
    objective_sleep_data = {
        'sleep_performance_state': 'medium',  # ç¡çœ è¡¨ç°ä¸€èˆ¬ï¼ˆå¯èƒ½å—é¥®é…’å½±å“ï¼‰
        'restorative_sleep': 'medium',        # æ¢å¤æ€§ç¡çœ ä¸­ç­‰
        'hrv_trend': 'slight_decline'         # HRVè½»å¾®ä¸‹é™
    }
    
    result1 = manager.add_evidence_and_update(objective_sleep_data)
    
    # =================== ç¬¬3æ­¥ï¼šå¡«å†™Hooperé‡è¡¨ ===================
    print(f"\nğŸ“ ç¬¬3æ­¥ï¼šæ‰‹åŠ¨å¡«å†™HooperæŒ‡æ•°é‡è¡¨")
    print("-"*50)
    print("â° æ—¶é—´ï¼šä»Šæ—©8:30")
    print("ğŸ–Šï¸  è¿åŠ¨å‘˜å¡«å†™ä¸»è§‚æ„Ÿå—é‡è¡¨")
    
    hooper_data = {
        'fatigue_hooper': 5,    # ç–²åŠ³åº¦ 5/7ï¼ˆä¸­é«˜ï¼‰
        'soreness_hooper': 3,   # é…¸ç—›åº¦ 3/7ï¼ˆä¸­ç­‰ï¼‰  
        'stress_hooper': 6,     # å‹åŠ›åº¦ 6/7ï¼ˆé«˜ï¼‰- å·¥ä½œå‹åŠ›+ç”Ÿç—…å½±å“
        'sleep_hooper': 3       # ç¡çœ è´¨é‡ 3/7ï¼ˆä¸€èˆ¬ï¼‰- é¥®é…’å½±å“
    }
    
    print(f"Hooperé‡è¡¨å¡«å†™: ç–²åŠ³ {hooper_data['fatigue_hooper']}/7, é…¸ç—› {hooper_data['soreness_hooper']}/7, å‹åŠ› {hooper_data['stress_hooper']}/7, ç¡çœ  {hooper_data['sleep_hooper']}/7")
    
    result2 = manager.add_evidence_and_update(hooper_data)
    
    # =================== ç¬¬4æ­¥ï¼šä¸‹åˆçªå‘çŠ¶å†µæ›´æ–° ===================
    print(f"\nğŸš¨ ç¬¬4æ­¥ï¼šä¸‹åˆçªå‘çŠ¶å†µ - æ„Ÿå†’ç—‡çŠ¶ç¡®è®¤")
    print("-"*50)
    print("â° æ—¶é—´ï¼šä»Šå¤©14:30")
    print("ğŸ“ è¿åŠ¨å‘˜åœ¨æ—¥å¿—ä¸­ç¡®è®¤æ„Ÿå†’ç—‡çŠ¶")
    
    # æ³¨æ„ï¼šç”Ÿç—…çŠ¶æ€ä¼šè‡ªåŠ¨ä»journalä¸­æ£€æµ‹åˆ°
    emergency_symptoms = {
        'subjective_fatigue': 'high',  # ä¸»è§‚ç–²åŠ³æ„Ÿçªç„¶å¢åŠ 
        'gi_symptoms': 'mild'          # è½»å¾®èƒƒè‚ ä¸é€‚
    }
    
    result3 = manager.add_evidence_and_update(emergency_symptoms)
    
    # =================== å±•ç¤ºå®Œæ•´çš„æ›´æ–°å†ç¨‹ ===================
    print("\n" + "="*70)
    print("ğŸ“ˆ å®Œæ•´çš„å‡†å¤‡åº¦è¯„ä¼°å†ç¨‹æ€»ç»“")
    print("="*70)
    
    summary = manager.get_daily_summary()
    
    print(f"ğŸ“… è¯„ä¼°æ—¥æœŸ: {summary['date']}")
    print(f"ğŸ‘¤ è¿åŠ¨å‘˜ID: {summary['user_id']}")
    print(f"ğŸ¯ æœ€ç»ˆå‡†å¤‡åº¦: {summary['final_readiness_score']}/100")
    print(f"ğŸ¥ æœ€ç»ˆè¯Šæ–­: {summary['final_diagnosis']}")
    print(f"ğŸ”„ æ€»æ›´æ–°æ¬¡æ•°: {summary['total_updates']}")
    
    print(f"\nğŸ“Š å‡†å¤‡åº¦åˆ†æ•°å˜åŒ–è½¨è¿¹:")
    initial_score = manager._get_readiness_score(manager.today_prior_probs)
    print(f"åˆå§‹å…ˆéªŒåˆ†æ•°: {initial_score}/100")
    
    update_labels = ["ç¡çœ HRVæ•°æ®", "Hooperé‡è¡¨", "çªå‘ç—‡çŠ¶"]
    for i, update in enumerate(summary['update_history']): 
        score = update['readiness_score']
        label = update_labels[i] if i < len(update_labels) else f"æ›´æ–°{i+1}"
        print(f"ç¬¬{i+1}æ¬¡æ›´æ–°å: {score}/100 (æ·»åŠ {label})")
    
    print(f"\nğŸ§  æ¦‚ç‡åˆ†å¸ƒå˜åŒ–å†ç¨‹:")
    print(f"{'çŠ¶æ€':>12} {'å…ˆéªŒ':>8} {'æœ€ç»ˆ':>8} {'å˜åŒ–':>8} {'è¶‹åŠ¿':>4}")
    print("-" * 40)
    for state in manager.states:
        prior_prob = summary['prior_probs'].get(state, 0)
        final_prob = summary['final_posterior_probs'].get(state, 0)
        change = final_prob - prior_prob
        trend = "ğŸ“ˆ" if change > 0.05 else "ğŸ“‰" if change < -0.05 else "â¡ï¸"
        print(f"{state:>12} {prior_prob:>8.3f} {final_prob:>8.3f} {change:>+8.3f} {trend:>4}")
    
    print(f"\nğŸ“‹ æœ€ç»ˆè¯æ®æ± è¯¦æƒ…:")
    evidence_categories = manager._categorize_evidence(summary['evidence_pool'])
    for category, evidence_list in evidence_categories.items():
        if evidence_list:
            print(f"  {category}: {len(evidence_list)}é¡¹ - {evidence_list}")
    
    print(f"\nğŸ”‘ å…³é”®è®¾è®¡éªŒè¯:")
    print(f"âœ… å…ˆéªŒæ¦‚ç‡å—æ—¥å¿—å½±å“ï¼šæ˜¨æ™šé¥®é…’ â†’ å½±å“ä»Šæ—¥é¢„æµ‹")
    print(f"âœ… åéªŒæ¦‚ç‡ç´¯ç§¯æ›´æ–°ï¼š[å›ºå®šå…ˆéªŒ] + [ç´¯ç§¯è¯æ®] = [å®æ—¶åéªŒ]") 
    print(f"âœ… è¯æ®ä¼˜å…ˆçº§ä½“ç°ï¼šHooperæŒ‡æ•° > å®¢è§‚æ•°æ® > Journalè¯æ®")
    print(f"âœ… æ—¥å¿—è‡ªåŠ¨æ¸…ç†ï¼šçŸ­æœŸè¡Œä¸ºå·²æ¸…ç†ï¼ŒæŒç»­çŠ¶æ€ä¿ç•™")
    
    print(f"\nğŸ‰ çœŸå®ä½¿ç”¨åœºæ™¯æ¨¡æ‹Ÿå®Œæˆï¼")
